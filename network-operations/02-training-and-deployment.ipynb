{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Operations Demo - Train, Test, and Deploy\n",
    "\n",
    "This project demonstrates how to build an automated machine-learning (ML) pipeline for predicting network outages based on network-device telemetry. This notebook is the second part (out of 2) of the demo. This part demonstrates how to train, test and deploy a model and use offline and real-time data from the feature store.\n",
    "\n",
    "**In this notebook:**\n",
    "* **Create a Feature Vector that consists of data joined from the three feature sets you created**\n",
    "* **Create an offline dataset from the feature vector to feed the ML training process**\n",
    "* **Run automated ML Pipeline which train, test, and deploy the model**\n",
    "* **Test the deployed real-time serving function**\n",
    "\n",
    "When you finish this notebook, you should have a running network-device failure prediction system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and init the MLRun project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-02-10 13:56:05,467 [info] loaded project network-operations from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mlrun\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Create the project\n",
    "project = mlrun.get_or_create_project('network-operations', \"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new Feature Vector\n",
    "The goal is to create a single dataset that contain datas from the static devices dataset, the device metrics, and the labels.\n",
    "You'll define a **Feature Vector** and specify the desired features. When the vector is retrieved the feature store automatically and correctly joins the data from the different feature sets based on the entity (index) keys and the timestamp values.\n",
    "\n",
    "To define and save the `device_features` feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the `device_features` Feature Vector\n",
    "fv = fstore.FeatureVector('device_features',\n",
    "                          features=['device_metrics.*', 'static.*'], \n",
    "                          label_feature='device_labels.is_error')\n",
    "\n",
    "# Save the Feature Vector to MLRun's feature store DB\n",
    "fv.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an offline dataset for the feature vector\n",
    "Once you have defined the feature vector and ingested some data, you can request the feature store to create an offline dataset, e.g. a snapshot of the data between the dates you want available to be loaded as parquet or csv files or as a pandas Dataframe.\n",
    "\n",
    "you can later reference the created offline dataset via a special artifact url (`fv.url`).\n",
    "\n",
    "**Make sure you run this AFTER the feature set data was ingested (using batch or real-time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-02-10 13:56:06,270 [info] wrote target: {'name': 'parquet', 'kind': 'parquet', 'path': 'v3io:///projects/network-operations-admin/FeatureStore/device_features/parquet/vectors/device_features-latest.parquet', 'status': 'ready', 'updated': '2022-02-10T13:56:06.270401+00:00', 'size': 55011}\n",
      "\n",
      "Training set shape: (480, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_utilization_avg_1h</th>\n",
       "      <th>cpu_utilization_avg_6h</th>\n",
       "      <th>cpu_utilization_min_1h</th>\n",
       "      <th>cpu_utilization_min_6h</th>\n",
       "      <th>cpu_utilization_max_1h</th>\n",
       "      <th>cpu_utilization_max_6h</th>\n",
       "      <th>throughput_avg_1h</th>\n",
       "      <th>throughput_avg_6h</th>\n",
       "      <th>throughput_min_1h</th>\n",
       "      <th>throughput_min_6h</th>\n",
       "      <th>...</th>\n",
       "      <th>models_8</th>\n",
       "      <th>models_9</th>\n",
       "      <th>country_A</th>\n",
       "      <th>country_B</th>\n",
       "      <th>country_C</th>\n",
       "      <th>country_D</th>\n",
       "      <th>country_E</th>\n",
       "      <th>country_F</th>\n",
       "      <th>country_G</th>\n",
       "      <th>is_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cpu_utilization_avg_1h  cpu_utilization_avg_6h  cpu_utilization_min_1h  \\\n",
       "0                   100.0                   100.0                   100.0   \n",
       "1                   100.0                   100.0                   100.0   \n",
       "2                   100.0                   100.0                   100.0   \n",
       "3                   100.0                   100.0                   100.0   \n",
       "4                   100.0                   100.0                   100.0   \n",
       "\n",
       "   cpu_utilization_min_6h  cpu_utilization_max_1h  cpu_utilization_max_6h  \\\n",
       "0                   100.0                   100.0                   100.0   \n",
       "1                   100.0                   100.0                   100.0   \n",
       "2                   100.0                   100.0                   100.0   \n",
       "3                   100.0                   100.0                   100.0   \n",
       "4                   100.0                   100.0                   100.0   \n",
       "\n",
       "   throughput_avg_1h  throughput_avg_6h  throughput_min_1h  throughput_min_6h  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   ...  models_8  models_9  country_A  country_B  country_C  country_D  \\\n",
       "0  ...         0         0          0          0          0          0   \n",
       "1  ...         0         0          0          0          0          0   \n",
       "2  ...         0         0          1          0          0          0   \n",
       "3  ...         0         0          1          0          0          0   \n",
       "4  ...         1         0          1          0          0          0   \n",
       "\n",
       "   country_E  country_F  country_G  is_error  \n",
       "0          1          0          0      True  \n",
       "1          1          0          0      True  \n",
       "2          0          0          0      True  \n",
       "3          0          0          0      True  \n",
       "4          0          0          0      True  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Request (get or create) the offline dataset from the feature store and save to a parquet target\n",
    "dataset_ref = fstore.get_offline_features(fv, target=mlrun.datastore.targets.ParquetTarget())\n",
    "\n",
    "# Get the generated offline dataset as a pandas DataFrame\n",
    "dataset = dataset_ref.to_dataframe()\n",
    "print(\"\\nTraining set shape:\", dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the dataset contains proper labels (must have both True & False values)\n",
    "unique = dataset.is_error.unique()\n",
    "assert len(unique) == 2, \"dataset does not contain both label values. ingest a bigger dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and deployment using the feature vector\n",
    "Now that the dataset is ready for training, you need to define the model training, testing and deployment process.\n",
    "\n",
    "Build an automated ML pipeline that uses pre-baked serverless training, testing and serving functions from [MLRun's functions marketplace](https://www.mlrun.org/marketplace/). The pipeline has three steps:\n",
    "* Train a model using data from the feature vector you created and save it to the model registry\n",
    "* Run model test/evaluation with a portion of the data\n",
    "* Deploy a real-time serving function that uses the newly trained model, and enrich/impute the features with data from the real-time feature vector \n",
    "\n",
    "You can see the [**workflow code**](./src/workflow.py). You can run this workflow locally, in a CI/CD framework, or over Kubeflow. In practice you can create different workflows for development and production.\n",
    "\n",
    "The workflow/pipeline can be executed using the MLRun SDK (`project.run()` method) or using CLI commands (`mlrun project`), and can run directly from the source repo (GIT). See details in MLRun [**Projects and Automation documentation**](https://docs.mlrun.org/en/latest/projects/overview.html).\n",
    "\n",
    "When you run the workflow you can set arguments and destination for the different artifacts. The pipeline progress is shown in the notebook. Alternatively you can check the progress, logs, artifacts, etc. in the MLRun UI.\n",
    "\n",
    "If you want to run the same using CLI, type:\n",
    "\n",
    "```python\n",
    "    mlrun project -n myproj -r ./src/workflow.py .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>Pipeline running (id=73730040-07dc-4de5-9f28-d7f48cdfc519), <a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd1.com/mlprojects/network-operations-admin/jobs/monitor-workflows/workflow/73730040-07dc-4de5-9f28-d7f48cdfc519\" target=\"_blank\"><b>click here</b></a> to view the details in MLRun UI</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: kfp Pages: 1 -->\n",
       "<svg width=\"206pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 205.60 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>kfp</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 201.5975,-112 201.5975,4 -4,4\"/>\n",
       "<!-- netops&#45;demo&#45;wfjww&#45;2234054694 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>netops&#45;demo&#45;wfjww&#45;2234054694</title>\n",
       "<polygon fill=\"#00ff00\" stroke=\"#000000\" points=\"122,-36 4,-36 0,-32 0,0 118,0 122,-4 122,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"118,-32 0,-32 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"118,-32 118,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"118,-32 122,-36 \"/>\n",
       "<text text-anchor=\"middle\" x=\"61\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">deploy&#45;serving</text>\n",
       "</g>\n",
       "<!-- netops&#45;demo&#45;wfjww&#45;2714578612 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>netops&#45;demo&#45;wfjww&#45;2714578612</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"169\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">test</text>\n",
       "</g>\n",
       "<!-- netops&#45;demo&#45;wfjww&#45;3111339042 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>netops&#45;demo&#45;wfjww&#45;3111339042</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"115\" cy=\"-90\" rx=\"33.2948\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"115\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n",
       "</g>\n",
       "<!-- netops&#45;demo&#45;wfjww&#45;3111339042&#45;&gt;netops&#45;demo&#45;wfjww&#45;2234054694 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>netops&#45;demo&#45;wfjww&#45;3111339042&#45;&gt;netops&#45;demo&#45;wfjww&#45;2234054694</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M102.4756,-73.3008C96.0174,-64.6899 87.9905,-53.9874 80.7236,-44.2981\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.3917,-42.0222 74.5916,-36.1222 77.7916,-46.2222 83.3917,-42.0222\"/>\n",
       "</g>\n",
       "<!-- netops&#45;demo&#45;wfjww&#45;3111339042&#45;&gt;netops&#45;demo&#45;wfjww&#45;2714578612 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>netops&#45;demo&#45;wfjww&#45;3111339042&#45;&gt;netops&#45;demo&#45;wfjww&#45;2714578612</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M127.5244,-73.3008C134.3399,-64.2135 142.9025,-52.7966 150.4753,-42.6996\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.3435,-44.7087 156.5435,-34.6087 147.7435,-40.5087 153.3435,-44.7087\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fd061bdc5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Run Results</h2>Workflow 73730040-07dc-4de5-9f28-d7f48cdfc519 finished, state=Succeeded<br>click the hyper links below to see detailed results<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"1375119b79c447c4b1f41dfd3265154d\"><a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd1.com/mlprojects/network-operations-admin/jobs/monitor/1375119b79c447c4b1f41dfd3265154d/overview\" target=\"_blank\" >...3265154d</a></div></td>\n",
       "      <td>Feb 10 14:04:10</td>\n",
       "      <td>completed</td>\n",
       "      <td>test</td>\n",
       "      <td><div class=\"dictlist\">label_column=is_error</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=1.0</div><div class=\"dictlist\">test-error=0.0</div><div class=\"dictlist\">rocauc=1.0</div><div class=\"dictlist\">brier_score=0.00031527777777777777</div><div class=\"dictlist\">f1-score=1.0</div><div class=\"dictlist\">precision_score=1.0</div><div class=\"dictlist\">recall_score=1.0</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"4e7a912d7d3647e297beaa1c0a0bf00c\"><a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd1.com/mlprojects/network-operations-admin/jobs/monitor/4e7a912d7d3647e297beaa1c0a0bf00c/overview\" target=\"_blank\" >...0a0bf00c</a></div></td>\n",
       "      <td>Feb 10 14:03:53</td>\n",
       "      <td>completed</td>\n",
       "      <td>train</td>\n",
       "      <td><div class=\"dictlist\">label_column=is_error</div><div class=\"dictlist\">model_pkg_class=sklearn.ensemble.RandomForestClassifier</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=1.0</div><div class=\"dictlist\">test-error=0.0</div><div class=\"dictlist\">rocauc=1.0</div><div class=\"dictlist\">brier_score=0.0016544554455445544</div><div class=\"dictlist\">f1-score=1.0</div><div class=\"dictlist\">precision_score=1.0</div><div class=\"dictlist\">recall_score=1.0</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"netops\"\n",
    "\n",
    "# run the workflow\n",
    "run_id = project.run(\n",
    "    workflow_path=\"./src/workflow.py\",\n",
    "    arguments={\"vector_uri\": fv.uri, \"model_name\": model_name}, \n",
    "    watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Live Model Endpoint\n",
    "To test the live model endpoint, first grab a list of IDs from the static feature set it produced. Then use these IDs and send them through a loop to the live endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab IDs from the static devices table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices sample: ['5366904160408' '4366213343194' '5300819942199' '7294710463338']\n"
     ]
    }
   ],
   "source": [
    "# Load the static feature set\n",
    "fset = fstore.get_feature_set('static')\n",
    "\n",
    "# Get a dataframe from the feature set\n",
    "devices = fset.to_dataframe().reset_index()['device'].values\n",
    "print('Devices sample:', devices[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send a sample ID to the model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-02-10 14:05:05,843 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-network-operations-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/netops/infer'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'f5c28ca9-3b52-4582-89fa-9caf80752ba3',\n",
       " 'model_name': 'netops',\n",
       " 'outputs': [False]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_fn = project.get_function('serving')\n",
    "serving_fn.invoke(path=f'/v2/models/{model_name}/infer', body={'inputs': [[devices[0]]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continously send IDs to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-02-10 14:05:07,665 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-network-operations-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/netops/infer'}\n",
      "Sent: [['5366904160408'], ['9089787659244']]\n",
      "Response: {'id': '5fab5012-31e1-4c93-99f7-910c5e10df93', 'model_name': 'netops', 'outputs': [False, False]}\n",
      "Predictions: [(['5366904160408'], False), (['9089787659244'], False)]\n",
      "> 2022-02-10 14:05:17,709 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-network-operations-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/netops/infer'}\n",
      "Sent: [['7190575638226'], ['6456808756864']]\n",
      "Response: {'id': '81ac75f1-00d7-412d-8eab-8d8e5d3719b1', 'model_name': 'netops', 'outputs': [False, False]}\n",
      "Predictions: [(['7190575638226'], False), (['6456808756864'], False)]\n",
      "> 2022-02-10 14:05:27,755 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-network-operations-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/netops/infer'}\n",
      "Sent: [['6796821902797'], ['5300819942199']]\n",
      "Response: {'id': '882ffa3f-cb1c-40ae-915b-8e80810c3a49', 'model_name': 'netops', 'outputs': [False, False]}\n",
      "Predictions: [(['6796821902797'], False), (['5300819942199'], False)]\n",
      "> 2022-02-10 14:05:37,801 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-network-operations-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/netops/infer'}\n",
      "Sent: [['5366904160408'], ['2133702096887']]\n",
      "Response: {'id': '43b458d7-8e59-4598-95b3-f0c350a20ca3', 'model_name': 'netops', 'outputs': [False, False]}\n",
      "Predictions: [(['5366904160408'], False), (['2133702096887'], False)]\n",
      "> 2022-02-10 14:05:47,851 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-network-operations-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/netops/infer'}\n",
      "Sent: [['5021644823083'], ['7453742823111']]\n",
      "Response: {'id': 'cdde1873-b9c0-483a-8771-4eae5f2a480d', 'model_name': 'netops', 'outputs': [False, False]}\n",
      "Predictions: [(['5021644823083'], False), (['7453742823111'], False)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "MSGS_TO_SEND = 5\n",
    "IDS_PER_MSG = 2\n",
    "TIMEOUT_BETWEEN_SENDS = 10\n",
    "for i in range(MSGS_TO_SEND):\n",
    "    ids_for_prediction = [[random.choice(devices)] for i in range(IDS_PER_MSG)]\n",
    "    resp = serving_fn.invoke(path=f'/v2/models/{model_name}/infer', body={'inputs': ids_for_prediction})\n",
    "    print('Sent:', ids_for_prediction)\n",
    "    print('Response:', resp)\n",
    "    print('Predictions:', list(zip(ids_for_prediction, resp['outputs'])))\n",
    "    time.sleep(TIMEOUT_BETWEEN_SENDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
