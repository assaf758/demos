{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Article Summarization and Keyword Extraction via NLP\n",
    "\n",
    "In this demo, we will create an NLP pipeline that will summarize and extract keywords from a news article URL. We will be using state-of-the-art transformer models such as BERT to perform these NLP tasks.\n",
    "\n",
    "Additionally, we will be using MLRun's real-time inference graphs to create the pipeline. This allows for easy containerization and deployment of our pipeline on top of a production-ready Kubernetes cluster.\n",
    "\n",
    "The full pipeline will do the following:\n",
    "1. Retrieve news article text and metadata from URL using newspaper3k\n",
    "2. Summarize article text via Huggingface pipeline using DistilBart model\n",
    "3. Extract article keywords via KeyBERT using BERT-embeddings and cosine similarity\n",
    "4. Remove the original article text from the response (optional)\n",
    "5. Persist record in KV table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Local Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.11.3 in /opt/conda/lib/python3.8/site-packages (4.11.3)\n",
      "Requirement already satisfied: newspaper3k==0.2.8 in /opt/conda/lib/python3.8/site-packages (0.2.8)\n",
      "Requirement already satisfied: keybert==0.5.0 in /opt/conda/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (2022.8.17)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (0.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (0.0.53)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (4.60.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (1.20.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (5.4.1)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (0.35.1)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (6.0.10)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (2.8.1)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (3.7)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (4.9.3)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (0.0.4)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (0.3)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (3.3.1)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (9.2.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /opt/conda/lib/python3.8/site-packages (from newspaper3k==0.2.8) (1.1.0)\n",
      "Requirement already satisfied: rich>=10.4.0 in /opt/conda/lib/python3.8/site-packages (from keybert==0.5.0) (12.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /opt/conda/lib/python3.8/site-packages (from keybert==0.5.0) (1.0.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in /opt/conda/lib/python3.8/site-packages (from keybert==0.5.0) (2.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4>=4.4.1->newspaper3k==0.2.8) (2.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from feedfinder2>=0.0.4->newspaper3k==0.2.8) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in /opt/conda/lib/python3.8/site-packages (from feedparser>=5.2.1->newspaper3k==0.2.8) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (4.3.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k==0.2.8) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k==0.2.8) (8.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.11.3) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (3.0.4)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from rich>=10.4.0->keybert==0.5.0) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.8/site-packages (from rich>=10.4.0->keybert==0.5.0) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert==0.5.0) (1.6.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert==0.5.0) (2.1.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert==0.5.0) (1.12.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert==0.5.0) (0.1.97)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert==0.5.0) (0.13.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in /opt/conda/lib/python3.8/site-packages (from tldextract>=2.0.1->newspaper3k==0.2.8) (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.11.3 newspaper3k==0.2.8 keybert==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MLRun Function\n",
    "Here we define the serverless function that will containerize and deploy our application. We can add dependencies and commands to the image build, define replicas for scaling, add environment variables, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-08-25 13:49:21,009 [info] created project nlp-demo and saved in MLRun DB\n"
     ]
    }
   ],
   "source": [
    "project_name = \"nlp-demo\"\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = mlrun.code_to_function(name=\"news-article-nlp\", filename=\"nlp_transformations.py\",\n",
    "                            kind=\"serving\", image='mlrun/ml-models')\n",
    "fn.spec.min_replicas = 1\n",
    "fn.spec.max_replicas = 1\n",
    "fn.spec.build.commands = [\n",
    "    \"python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert==0.5.0\",\n",
    "    \"python -c 'from transformers import pipeline; pipeline(\\\"summarization\\\")'\",\n",
    "    \"python -c 'from keybert import KeyBERT; KeyBERT()'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Real-Time Serving Graph\n",
    "Here we will orchestrate the functions and classes we want to run in our pipeline. The source code for these functions is located in `project/nlp_transformations.py`. Notice, this is the same file we used when running `code_to_function` in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"bigdata\"\n",
    "table_path = f\"nlp-{os.getenv('V3IO_USERNAME')}\"\n",
    "key = \"title\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KV will soon be supported on community edition !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"727pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 726.84 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 722.84,-40 722.84,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"31.43,-0.05 33.2,-0.15 34.96,-0.3 36.69,-0.49 38.39,-0.74 40.05,-1.03 41.67,-1.36 43.23,-1.75 44.73,-2.18 46.17,-2.65 47.54,-3.16 48.84,-3.71 50.06,-4.31 51.2,-4.94 52.25,-5.61 53.22,-6.31 54.09,-7.04 54.87,-7.8 55.56,-8.59 56.15,-9.41 56.65,-10.25 57.05,-11.11 57.36,-11.99 57.58,-12.89 57.7,-13.8 57.73,-14.72 57.68,-15.65 57.54,-16.59 57.31,-17.53 57.01,-18.47 56.63,-19.41 56.18,-20.35 55.66,-21.28 55.08,-22.2 54.43,-23.11 53.72,-24.01 52.97,-24.89 52.16,-25.75 51.3,-26.59 50.41,-27.41 49.48,-28.2 48.51,-28.96 47.51,-29.69 46.48,-30.39 45.43,-31.06 44.35,-31.69 43.26,-32.29 42.15,-32.84 41.02,-33.35 39.89,-33.82 38.74,-34.25 37.58,-34.64 36.42,-34.97 35.24,-35.26 34.07,-35.51 32.89,-35.7 31.71,-35.85 30.52,-35.95 29.34,-36 28.15,-36 26.96,-35.95 25.78,-35.85 24.6,-35.7 23.42,-35.51 22.24,-35.26 21.07,-34.97 19.91,-34.64 18.75,-34.25 17.6,-33.82 16.46,-33.35 15.34,-32.84 14.23,-32.29 13.13,-31.69 12.06,-31.06 11.01,-30.39 9.98,-29.69 8.98,-28.96 8.01,-28.2 7.08,-27.41 6.18,-26.59 5.33,-25.75 4.52,-24.89 3.76,-24.01 3.06,-23.11 2.41,-22.2 1.83,-21.28 1.3,-20.35 0.85,-19.41 0.47,-18.47 0.17,-17.53 -0.05,-16.59 -0.19,-15.65 -0.25,-14.72 -0.21,-13.8 -0.09,-12.89 0.13,-11.99 0.43,-11.11 0.84,-10.25 1.34,-9.41 1.93,-8.59 2.62,-7.8 3.4,-7.04 4.27,-6.31 5.24,-5.61 6.29,-4.94 7.43,-4.31 8.65,-3.71 9.94,-3.16 11.31,-2.65 12.75,-2.18 14.26,-1.75 15.82,-1.36 17.44,-1.03 19.1,-0.74 20.79,-0.49 22.53,-0.3 24.28,-0.15 26.06,-0.05 27.85,0 29.64,0 31.43,-0.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"28.74\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<!-- fetch_article -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>fetch_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"148.08\" cy=\"-18\" rx=\"54.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.08\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">fetch_article</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;fetch_article -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;fetch_article</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.25,-18C65.21,-18 74.25,-18 83.45,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.46,-21.5 93.46,-18 83.46,-14.5 83.46,-21.5\"/>\n",
       "</g>\n",
       "<!-- summarize_article -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>summarize_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"315.37\" cy=\"-18\" rx=\"76.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.37\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">summarize_article</text>\n",
       "</g>\n",
       "<!-- fetch_article&#45;&gt;summarize_article -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>fetch_article&#45;&gt;summarize_article</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.75,-18C210.94,-18 219.58,-18 228.26,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.46,-21.5 238.46,-18 228.46,-14.5 228.46,-21.5\"/>\n",
       "</g>\n",
       "<!-- extract_keywords -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>extract_keywords</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"501.51\" cy=\"-18\" rx=\"73.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"501.51\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">extract_keywords</text>\n",
       "</g>\n",
       "<!-- summarize_article&#45;&gt;extract_keywords -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>summarize_article&#45;&gt;extract_keywords</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M392.33,-18C400.71,-18 409.28,-18 417.73,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"417.98,-21.5 427.98,-18 417.98,-14.5 417.98,-21.5\"/>\n",
       "</g>\n",
       "<!-- filter_article -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>filter_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"664.9\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"664.9\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">filter_article</text>\n",
       "</g>\n",
       "<!-- extract_keywords&#45;&gt;filter_article -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>extract_keywords&#45;&gt;filter_article</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M575.18,-18C583.53,-18 592,-18 600.22,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"600.48,-21.5 610.48,-18 600.48,-14.5 600.48,-21.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa8bf2b96d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = fn.set_topology(\"flow\", engine=\"async\")\n",
    "\n",
    "if not os.environ.get('MLRUN_CE'):\n",
    "    graph.to(name=\"fetch_article\", handler=\"fetch_article\")\\\n",
    "         .to(name=\"summarize_article\", class_name=\"SummarizeArticle\")\\\n",
    "         .to(name=\"extract_keywords\", class_name=\"ExtractKeywords\")\\\n",
    "         .to(name=\"filter_article\", handler=\"filter_article\")\\\n",
    "         .to(name=\"kv_format\", handler=\"kv_format\", full_event=True)\\\n",
    "         .to(name=\"write_to_kv\", class_name=\"storey.NoSqlTarget\", table=f\"v3io:///{container}/{table_path}\").respond()\n",
    "    \n",
    "else:\n",
    "    graph.to(name=\"fetch_article\", handler=\"fetch_article\")\\\n",
    "         .to(name=\"summarize_article\", class_name=\"SummarizeArticle\")\\\n",
    "         .to(name=\"extract_keywords\", class_name=\"ExtractKeywords\")\\\n",
    "         .to(name=\"filter_article\", handler=\"filter_article\")\\\n",
    "\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Pipeline Locally (using simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    }
   ],
   "source": [
    "# import the step functions for simulation\n",
    "from nlp_transformations import *\n",
    "\n",
    "# create a mock server (simulator)\n",
    "server = fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd8b2b697edcd4bb7947ccbccb9e1043f'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the pipeline\n",
    "server.test(\"/\", body={\"url\" : \"https://www.cnn.com/2021/11/01/politics/vaccine-rules-osha/index.html\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containerize and Deploy Pipeline on K8s\n",
    "Here we easily containerize and deploy our application to our K8s cluster with a single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-08-25 13:49:27,593 [info] Starting remote function deploy\n",
      "2022-08-25 13:49:27  (info) Deploying function\n",
      "2022-08-25 13:49:27  (info) Building\n",
      "2022-08-25 13:49:27  (info) Staging files and preparing base images\n",
      "2022-08-25 13:49:27  (info) Building processor image\n",
      "2022-08-25 13:52:07  (info) Build complete\n",
      "2022-08-25 13:52:19  (info) Function deploy complete\n",
      "> 2022-08-25 13:52:20,593 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-nlp-demo-jovyan-news-article-nlp.mlrun.svc.cluster.local:8080'], 'external_invocation_urls': ['localhost:31293']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://localhost:31293'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.spec.readinessTimeoutSeconds = 60 * 20  # 20 minutes.\\n\",\n",
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Pipeline with URLs From Various News Sources \n",
    "Here we can test the pipeline with various news sources. This pipeline should work with any source compatible with the `newspaper3k` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-08-25 13:52:20,622 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-jovyan-news-article-nlp.mlrun.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '062ea845-362e-4195-a663-bd7eb4ca060b'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://www.cnn.com/2021/11/01/politics/vaccine-rules-osha/index.html\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-08-25 13:52:20,632 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-jovyan-news-article-nlp.mlrun.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '1eb24abf-a111-40a6-ab60-0acf2973a893'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://www.cnn.com/travel/article/americans-bought-bargain-homes-in-italy-cmd/index.html\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-08-25 13:52:20,640 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-jovyan-news-article-nlp.mlrun.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '6ee1bf2e-33c3-4860-b419-1f5f18e78d1a'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://www.npr.org/2021/11/01/1050212278/public-school-meals-students-labor-issues\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-08-25 13:52:20,648 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-jovyan-news-article-nlp.mlrun.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '11fc956f-f308-42b9-b794-ce3db3ad3e36'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://abcnews.go.com/Entertainment/wireStory/jon-bon-jovi-tests-positive-covid-19-cancels-80903055\",\n",
    "          \"filter_article\" : False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define KV Table Schema for Dashboard\n",
    "While a schema is not required to write records to a table, it is required for the table to be displayed in a Grafana dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get('MLRUN_CE'):\n",
    "    import v3io.dataplane\n",
    "\n",
    "    v3io_client = v3io.dataplane.Client()\n",
    "\n",
    "    v3io_client.kv.create_schema(\n",
    "        container=container,\n",
    "        table_path=table_path,\n",
    "        key=key,\n",
    "        fields = [\n",
    "            {'name': 'url',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'filter_article',\n",
    "             'type': 'boolean',\n",
    "             'nullable': False},\n",
    "            {'name': 'title',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'authors',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'publish_date',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'original_text',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'summarized_text',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'keywords',\n",
    "             'type': 'string',\n",
    "             'nullable': False}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the pipeline, we will be able to visualize the article summary, keywords, and metadata in a Grafana dashboard. The JSON file for the dashboard is available under `grafana_dashboard.json`.\n",
    "\n",
    "After importing into Grafana and running the pipeline above, the dashboard will look something like the following:\n",
    "![](./dashboard_preview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
