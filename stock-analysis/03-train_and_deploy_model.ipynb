{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **steps**\n",
    "> * Run notebook ingest_stocks\n",
    "> * Run notebook ingest_news\n",
    "> * Create feature vector\n",
    "> * Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-19 14:47:49,620 [info] loaded project stocks from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "project = mlrun.get_or_create_project(name='stocks',user_project=True, context=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of features we will be using\n",
    "features = ['stocks.*',\n",
    "            'news.sentiment',\n",
    "            ]\n",
    "\n",
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Define the feature vector name for future reference\n",
    "fv_name = 'stocks'\n",
    "\n",
    "# Define the feature vector using our Feature Store (fstore)\n",
    "transactions_fv = fstore.FeatureVector(fv_name, \n",
    "                          features, \n",
    "                          description='stocks information')\n",
    "\n",
    "# Save the feature vector in the Feature Store\n",
    "transactions_fv.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MLRunInvalidArgumentError",
     "evalue": "feature news.sentiment not found in feature set news",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMLRunInvalidArgumentError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c5c6ea33242a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_offline_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfv_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_timestamp_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.sentiment.unique()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-avia/lib/python3.7/site-packages/mlrun/feature_store/api.py\u001b[0m in \u001b[0;36mget_offline_features\u001b[0;34m(feature_vector, entity_rows, entity_timestamp_column, target, run_config, drop_columns, start_time, end_time, with_indexes, update_stats, engine, engine_args)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mend_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mwith_indexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indexes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mupdate_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-avia/lib/python3.7/site-packages/mlrun/feature_store/retrieval/base.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, entity_rows, entity_timestamp_column, target, drop_columns, start_time, end_time, with_indexes, update_stats)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# retrieve the feature set objects/fields needed for the vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         feature_set_objects, feature_set_fields = self.vector.parse_features(\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mupdate_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set_fields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-avia/lib/python3.7/site-packages/mlrun/feature_store/feature_vector.py\u001b[0m in \u001b[0;36mparse_features\u001b[0;34m(self, offline, update_stats)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     raise mlrun.errors.MLRunInvalidArgumentError(\n\u001b[0;32m--> 352\u001b[0;31m                         \u001b[0;34mf\"feature {feature} not found in feature set {feature_set}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                     )\n\u001b[1;32m    354\u001b[0m                 \u001b[0madd_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMLRunInvalidArgumentError\u001b[0m: feature news.sentiment not found in feature set news"
     ]
    }
   ],
   "source": [
    "# Get offline feature vector as dataframe and save the dataset to parquet\n",
    "import datetime\n",
    "start_time = datetime.datetime.now()-datetime.timedelta(7)\n",
    "end_time = datetime.datetime.now()-datetime.timedelta(0)\n",
    "train_dataset = fstore.get_offline_features(fv_name,start_time=start_time,end_time=end_time, entity_timestamp_column = 'Datetime')\n",
    "train_dataset.to_dataframe().head()#.sentiment.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.serving.ServingRuntime at 0x7f6649a3e210>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# getting our model training function\n",
    "project.set_function(os.path.join(os.getcwd(),'src','train_stocks.py'),\n",
    "                     name='train_stocks', kind='job', image='mlrun/ml-models')\n",
    "\n",
    "\n",
    "project.set_function(os.path.join(os.getcwd(),'src','train_stocks.py'),\n",
    "                     name='serving', kind='serving', image='mlrun/ml-models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and save workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflow.py\n",
    "import mlrun\n",
    "from kfp import dsl\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"Stocks Prediction Pipeline\",\n",
    "    description=\"predicting stock prices using yahoo api with sentiment analysis\"\n",
    ")\n",
    "\n",
    "def kfpipeline(vector_name:str,\n",
    "               seq_size:int = 5,\n",
    "               batch_size:int = 32,\n",
    "               hidden_dim:int = 10,\n",
    "               n_layers:int = 4,\n",
    "               epochs:int = 3,\n",
    "               start_time:int = 7,\n",
    "               end_time:int = 0,\n",
    "               model_filepath = './'\n",
    "               ):\n",
    "    \n",
    "    project = mlrun.get_current_project()\n",
    "    \n",
    "    preprocess = project.get_function('train_stocks').apply(mlrun.auto_mount())\n",
    "\n",
    "    preprocess_run = mlrun.run_function(name='train_stocks',\n",
    "                                        function='train_stocks',\n",
    "                                        handler='train_stocks',\n",
    "                                        params={'context':context,\n",
    "                                                'hidden_dim':hidden_dim,\n",
    "                                                'n_layers':n_layers,\n",
    "                                                'epochs':epochs, \n",
    "                                                'vector_name':vector_name,\n",
    "                                                'seq_size':seq_size,\n",
    "                                                'start_time':start_time,\n",
    "                                                'end_time':end_time,\n",
    "                                                'batch_size':batch_size,\n",
    "                                                'model_filepath':model_filepath},\n",
    "                                       outputs=[\"model\"])\n",
    "    \n",
    "    \n",
    "    # deploying serving function\n",
    "    serving_function = project.get_function(\"serving\")\n",
    "    # Mount it:\n",
    "    serving_function.apply(mlrun.mount_v3io())\n",
    "    # Set the topology and get the graph object:\n",
    "    graph = serving_function.set_topology(\"flow\", engine=\"async\")\n",
    "    # Build the serving graph:\n",
    "    graph.to(class_name=\"mlrun.frameworks.pytorch.PyTorchModelServer\", model_name='pytorch_stocks_model', model_path=str(preprocess_run.outputs[\"model\"]))\\\n",
    "         \n",
    "    \n",
    "    # Set the desired requirements:\n",
    "    serving_function.with_requirements(requirements=['yfinance','yahoo_fin'])\n",
    "    # Deploy the serving function:\n",
    "    mlrun.deploy_function(\"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file:\n",
    "workflow_name = \"stocks_workflow\"\n",
    "project.set_workflow(workflow_name, \"workflow.py\")\n",
    "\n",
    "# Save the project:\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-05-19 12:45:12,583 [info] submitted pipeline stocks-avia-stocks_workflow 2022-05-19 12-45-12 id=d1d43b0f-32f9-4852-8ac8-c66b9eebb59a\n",
      "> 2022-05-19 12:45:12,584 [info] Pipeline run id=d1d43b0f-32f9-4852-8ac8-c66b9eebb59a, check UI for progress\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Pipeline started in project stocks-avia id=d1d43b0f-32f9-4852-8ac8-c66b9eebb59a<div><a href=\"https://dashboard.default-tenant.app.app-lab-eks-b71.iguazio-cd0.com/mlprojects/stocks-avia/jobs/monitor-workflows/workflow/d1d43b0f-32f9-4852-8ac8-c66b9eebb59a\" target=\"_blank\">click here to view progress</a></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d1d43b0f-32f9-4852-8ac8-c66b9eebb59a"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.run(name=workflow_name,\n",
    "            arguments={\n",
    "                \"vector_name\":\"stocks\",\n",
    "                \"seq_size\": 5,\n",
    "                \"batch_size\": 32,\n",
    "                \"hidden_dim\": 10,\n",
    "                \"n_layers\": 4,\n",
    "                \"epochs\": 3,\n",
    "                \"start_time\":7,\n",
    "                \"end_time\":0,\n",
    "                \"model_filepath\":os.path.join(os.getcwd(),'src')\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
