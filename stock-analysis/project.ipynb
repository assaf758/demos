{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks Analysis Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both server & client are aligned (0.9.0rc1).\n"
     ]
    }
   ],
   "source": [
    "!/User/align_mlrun.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stocks project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-11-29 09:16:38,659 [info] created and saved project stocks-avia\n",
      "Project name: stocks-avia\n",
      "Artifacts path: v3io:///projects/{{run.project}}/artifacts\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import os\n",
    "import mlrun\n",
    "\n",
    "# Set the base project name\n",
    "project_name_base = 'stocks'\n",
    "# Initialize the MLRun environment and save the project name and artifacts path\n",
    "project_name, artifact_path = mlrun.set_environment(project=project_name_base,\n",
    "                                                    user_project=True)\n",
    "\n",
    "project_path = path.abspath('./')\n",
    "\n",
    "project = mlrun.new_project(project_name_base,\n",
    "                            context=project_path,                           \n",
    "                            user_project=True)\n",
    "                                                    \n",
    "# Display the current project name and artifacts path\n",
    "print(f'Project name: {project_name}')\n",
    "print(f'Artifacts path: {artifact_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "# Set functions to project\n",
    "project.set_function('code/00-train-sentiment-analysis-model.ipynb', name='bert_sentiment_classifier_trainer',kind = 'job')\n",
    "project.set_function(\"code/01-function_invoker.ipynb\", name='func_invoke',kind = 'job')\n",
    "\n",
    "project.set_function('code/02-read-stocks.ipynb', name='stocks_reader',kind = 'nuclio',\n",
    "                     image=\"mlrun/mlrun\")\n",
    "\n",
    "project.set_function('code/03-read-news.ipynb', name='news_reader',kind = 'nuclio',\n",
    "                     image=\"mlrun/mlrun\")\n",
    "\n",
    "project.set_function('code/04-stream-viewer.ipynb', name='stream_viewer', kind=\"nuclio\",\n",
    "                     image='mlrun/mlrun')\n",
    "\n",
    "project.set_function('hub://sentiment_analysis_serving', name='sentiment_analysis_server')\n",
    "\n",
    "project.set_function('code/05-read-vector.ipynb', name='vector_reader', kind='nuclio',\n",
    "                     image='mlrun/mlrun')\n",
    "\n",
    "project.set_function(\"code/06-model_training.ipynb\", name='rnn_model_training', kind='nuclio',\n",
    "                     image=\"mlrun/ml-models-gpu\")\n",
    "\n",
    "project.set_function(\"code/07-model_prediction.ipynb\", name='rnn_model_prediction', kind ='nuclio',\n",
    "                     image='mlrun/mlrun')\n",
    "\n",
    "project.set_function(\"code/08-grafana.ipynb\", name='grafana_view', kind='job',\n",
    "                     image='mlrun/mlrun')\n",
    "\n",
    "project.set_function(\"hub://rnn_serving\",name=\"rnn_serving\",kind = \"serving\")\n",
    "\n",
    "project.func('news_reader').spec.max_replicas = 1\n",
    "\n",
    "# Declaring project name for later use\n",
    "project.spec.params = {}\n",
    "project.spec.params[\"PROJECT_NAME\"] = project_name\n",
    "project.spec.params[\"ARTIFACT_PATH\"] = artifact_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a pre-trained model (optional)\n",
    "Since running the [training](training/bert_sentiment_classification.ipynb) part to achieve good results may take some time, we had already trained and uploaded a model to a public location.  \n",
    "You can easily download it by running the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to change the location of the source data, set the `SAMPLE_DATA_SOURCE_URL_PREFIX` environment variable.\n",
    "\n",
    "For example, set it to `/v3io/projects/demos-data/iguazio/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘/User/aviaIguazio/demos/stock-analysis/models/model.pt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this to download the pre-trained model to your `models` directory\n",
    "url_prefix = os.environ.get('SAMPLE_DATA_SOURCE_URL_PREFIX', 'https://s3.wasabisys.com/iguazio/')\n",
    "\n",
    "import os\n",
    "model_location = f'{url_prefix.rstrip(\"/\")}/data/stock-analysis/model.pt'\n",
    "saved_models_directory = os.path.join(os.path.abspath('./'), 'models')\n",
    "\n",
    "# Create paths\n",
    "os.makedirs(saved_models_directory, exist_ok=1)\n",
    "model_filepath = os.path.join(saved_models_directory, os.path.basename(model_location))\n",
    "\n",
    "if \"http\" in model_location:\n",
    "    ! wget -nc -P {saved_models_directory} {model_location}\n",
    "else:\n",
    "    ! cp {model_location} {saved_models_directory}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘/User/aviaIguazio/demos/stock-analysis/models/rnn_model.h5’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this to download the pre-trained model to your `models` directory\n",
    "url_prefix = os.environ.get('SAMPLE_DATA_SOURCE_URL_PREFIX', 'https://s3.wasabisys.com/iguazio/')\n",
    "\n",
    "import os\n",
    "rnn_model_location = f'{url_prefix.rstrip(\"/\")}/models/function-marketplace-models/rnn_serving/rnn_model.h5'\n",
    "rnn_saved_models_directory = os.path.join(os.path.abspath('./'), 'models')\n",
    "\n",
    "# Create paths\n",
    "os.makedirs(rnn_saved_models_directory, exist_ok=1)\n",
    "rnn_model_filepath = os.path.join(rnn_saved_models_directory, os.path.basename(rnn_model_location))\n",
    "\n",
    "if \"http\" in rnn_model_location:\n",
    "    ! wget -nc -P {rnn_saved_models_directory} {rnn_model_location}\n",
    "else:\n",
    "    ! cp {rnn_model_location} {rnn_saved_models_directory}\n",
    "#https://s3.wasabisys.com/iguazio/models/function-marketplace-models/rnn_serving/rnn_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7f0024620350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add model \n",
    "project.func('sentiment_analysis_server').add_model(\"model1\", class_name='SentimentClassifierServing', model_path=model_filepath)\n",
    "project.func(\"rnn_serving\").add_model(\"model2\",class_name=\"RNN_Model_Serving\",model_path = rnn_saved_models_directory) # make sure only one .h5 model is saved there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import auto_mount, mlconf, load_project\n",
    "import os\n",
    "from nuclio.triggers import V3IOStreamTrigger, CronTrigger\n",
    "import re \n",
    "\n",
    "funcs = {}\n",
    "\n",
    "# Directories and Paths\n",
    "projdir = os.path.abspath('./')\n",
    "project = load_project(projdir)\n",
    "project_name = project.spec.params.get(\"PROJECT_NAME\")\n",
    "artifact_path = project.spec.params.get(\"ARTIFACT_PATH\")\n",
    "model_filepath = os.path.join(projdir, 'models', 'model.pt') # Previously saved model if downloaded\n",
    "rnn_model_path = os.path.join(projdir, 'models', 'rnn_model.h5')\n",
    "reviews_datafile = os.path.join(projdir, 'data', 'reviews.csv')\n",
    "\n",
    "\n",
    "# Performence limit\n",
    "max_replicas = 1\n",
    "\n",
    "# Readers cron interval\n",
    "readers_cron_interval = '300s'\n",
    "\n",
    "# Training GPU Allocation\n",
    "# Set to 0 if no gpus are to be used\n",
    "training_gpus = 0\n",
    "\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        # Add V3IO Mount\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "        # Always pull images to keep updates\n",
    "        f.spec.image_pull_policy = 'Always'\n",
    "    \n",
    "    # Define inference-stream related triggers\n",
    "    functions['sentiment_analysis_server'].apply(auto_mount())\n",
    "    functions['sentiment_analysis_server'].spec.readiness_timeout = 500\n",
    "    functions['sentiment_analysis_server'].set_config('readinessTimeoutSeconds', 500)\n",
    "    functions['rnn_serving'].apply(auto_mount())\n",
    "    functions['rnn_serving'].spec.readiness_timeout = 500\n",
    "    functions['rnn_serving'].set_config('readinessTimeoutSeconds', 500)\n",
    "    \n",
    "    \n",
    "    # Adept image to use CPU if a GPU is not assigned\n",
    "    if training_gpus == 0:\n",
    "        functions['sentiment_analysis_server'].spec.base_spec['spec']['build']['baseImage']='mlrun/ml-models'\n",
    "        functions['bert_sentiment_classifier_trainer'].spec.image='mlrun/ml-models'\n",
    "    \n",
    "    # Add triggers\n",
    "    functions['stocks_reader'].add_trigger('cron', CronTrigger(readers_cron_interval))\n",
    "    functions['news_reader'].add_trigger('cron', CronTrigger(readers_cron_interval))\n",
    "    functions['rnn_model_training'].add_trigger('cron', CronTrigger('12h'))\n",
    "    \n",
    "    # Set max replicas for resource limits\n",
    "    functions['sentiment_analysis_server'].spec.max_replicas = max_replicas\n",
    "    functions['news_reader'].spec.max_replicas = max_replicas\n",
    "    functions['stocks_reader'].spec.max_replicas = max_replicas\n",
    "    \n",
    "    # Add GPU for training\n",
    "    functions['bert_sentiment_classifier_trainer'].gpus(training_gpus)\n",
    "    \n",
    "    project.func('news_reader').spec.max_replicas = 1\n",
    "\n",
    "    # Declare function base image to build (Job and not a nuclio funciton)\n",
    "    functions['func_invoke'].spec.image = \"mlrun/mlrun\"\n",
    "    functions['bert_sentiment_classifier_trainer'].spec.build.commands = ['pip install transformers==3.0.1', 'pip install torch==1.6.0']\n",
    "    functions['stocks_reader'].spec.build.commands = ['pip install lxml', 'pip install yfinance','pip install v3io_frames']\n",
    "    functions['news_reader'].spec.build.commands = ['pip install beautifulsoup4', 'pip install v3io_frames']\n",
    "    functions['stream_viewer'].spec.build.commands = ['pip install v3io']\n",
    "    functions['grafana_view'].spec.build.commands = ['pip install git+https://github.com/v3io/grafwiz --upgrade', 'pip install v3io_frames', 'pip install attrs==19.1.0']\n",
    "    functions['sentiment_analysis_server'].add_model(\"model1\", class_name='SentimentClassifierServing', model_path=model_filepath)\n",
    "    functions['rnn_serving'].add_model(\"model2\",class_name=\"RNN_Model_Serving\",model_path = rnn_model_path)  \n",
    "@dsl.pipeline(\n",
    "    name='Stocks demo deployer',\n",
    "    description='Up to RT Stocks ingestion and analysis'\n",
    ")\n",
    "def kfpipeline(\n",
    "    # General\n",
    "    V3IO_CONTAINER = 'users',\n",
    "    STOCKS_TSDB_TABLE = os.getenv('V3IO_USERNAME') + '/stocks/stocks_tsdb',\n",
    "    STOCKS_KV_TABLE = os.getenv('V3IO_USERNAME') + '/stocks/stocks_kv',\n",
    "    STOCKS_STREAM = os.getenv('V3IO_USERNAME') + '/stocks/stocks_stream',\n",
    "    RUN_TRAINER: bool = False,\n",
    "    \n",
    "    # Trainer\n",
    "    pretrained_model = 'bert-base-cased',\n",
    "    reviews_dataset = reviews_datafile,\n",
    "    models_dir = 'models',\n",
    "    model_filename = 'bert_sentiment_analysis_model.pt',\n",
    "    n_classes: int = 3,\n",
    "    MAX_LEN: int = 128,\n",
    "    BATCH_SIZE: int = 16,\n",
    "    EPOCHS: int =  2,\n",
    "    random_state: int = 42,\n",
    "    \n",
    "    # stocks reader\n",
    "    STOCK_LIST: list = ['GOOGL', 'MSFT', 'AMZN', 'AAPL', 'INTC'],\n",
    "    EXPRESSION_TEMPLATE = \"symbol='{symbol}';price={price};volume={volume};last_updated='{last_updated}'\",\n",
    "    \n",
    "    # Sentiment analysis server\n",
    "    model_name = 'bert_classifier_v1',\n",
    "    model_filepath = model_filepath # if not trained\n",
    "    \n",
    "    ):\n",
    "    \n",
    "    with dsl.Condition(RUN_TRAINER == True):\n",
    "        deployer = funcs['bert_sentiment_classifier_trainer'].deploy_step()\n",
    "                \n",
    "        trainer = funcs['bert_sentiment_classifier_trainer'].as_step(name='bert_sentiment_classifier_trainer',\n",
    "                                                                     handler='train_sentiment_analysis_model',\n",
    "                                                                     params={'pretrained_model': pretrained_model,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'models_dir': models_dir,\n",
    "                                                                             'model_filename': model_filename,\n",
    "                                                                             'n_classes': n_classes,\n",
    "                                                                             'MAX_LEN': MAX_LEN,\n",
    "                                                                             'BATCH_SIZE': BATCH_SIZE,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'random_state': random_state},\n",
    "                                                                     inputs={'reviews_dataset': reviews_dataset},\n",
    "                                                                     outputs=['bert_sentiment_analysis_model'],\n",
    "                                                                     image=deployer.outputs['image']).after(deployer)\n",
    "        \n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step().after(trainer)\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint'],\n",
    "                                                            'PROJECT_NAME' : project_name,\n",
    "                                                            'ARTIFACT_PATH' : artifact_path}).after(sentiment_server)\n",
    "        \n",
    "        news_reader_invok1 = funcs['func_invoke'].as_step(params = {\"endpoint\" : news_reader.outputs[\"endpoint\"]},\n",
    "                                                             handler=\"handler\").after(news_reader)\n",
    "            \n",
    "    with dsl.Condition(RUN_TRAINER == False):\n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step()\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint'],\n",
    "                                                            'PROJECT_NAME' : project_name,\n",
    "                                                            'ARTIFACT_PATH' : artifact_path}).after(sentiment_server)\n",
    "        \n",
    "        \n",
    "        \n",
    "        news_reader_invok2 = funcs['func_invoke'].as_step(params = {\"endpoint\" : news_reader.outputs[\"endpoint\"]},\n",
    "                                                             handler=\"handler\").after(news_reader)\n",
    "    \n",
    "    stocks_reader = funcs['stocks_reader'].deploy_step(env={'STOCK_LIST': STOCK_LIST,\n",
    "                                                            'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'STOCKS_KV_TABLE': STOCKS_KV_TABLE,\n",
    "                                                            'EXPRESSION_TEMPLATE': EXPRESSION_TEMPLATE,\n",
    "                                                            'PROJECT_NAME' : project_name,\n",
    "                                                            'ARTIFACT_PATH' : artifact_path})\n",
    "    \n",
    "    stream_viewer = funcs['stream_viewer'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM}).after(news_reader_invok1,news_reader_invok2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    vector_viewer = funcs['vector_reader'].deploy_step(env={'PROJECT_NAME' : project_name,\n",
    "                                                            'ARTIFACT_PATH' : artifact_path}).after(stocks_reader,news_reader_invok1,news_reader_invok2)\n",
    "    \n",
    "    \n",
    "    rnn_model_training_deployer = funcs[\"rnn_model_training\"].deploy_step(env={'model_path': rnn_model_path,\n",
    "                                                                               'PROJECT_NAME' : project_name,\n",
    "                                                                               'ARTIFACT_PATH' : artifact_path})\n",
    "    \n",
    "    rnn_model_training_invoker = funcs['func_invoke'].as_step(params = {\"endpoint\" : rnn_model_training_deployer.outputs[\"endpoint\"]},\n",
    "                                                             handler=\"handler\").after(rnn_model_training_deployer,vector_viewer)\n",
    "    \n",
    "    rnn_serving = funcs['rnn_serving'].deploy_step().after(rnn_model_training_invoker)\n",
    "    \n",
    "    rnn_model_prediction = funcs[\"rnn_model_prediction\"].deploy_step(env = {\"endpoint\":rnn_serving.outputs['endpoint'],\n",
    "                                                                            'ARTIFACT_PATH' : artifact_path}).after(rnn_serving)\n",
    "    \n",
    "    grafana_viewer = funcs[\"grafana_view\"].deploy_step()\n",
    "    \n",
    "    grafana_viewer = funcs[\"grafana_view\"].as_step(params = {\"streamview_url\" : stream_viewer.outputs[\"endpoint\"],\n",
    "                                                             \"readvector_url\" : vector_viewer.outputs[\"endpoint\"],\n",
    "                                                             \"rnn_serving_url\" : rnn_model_prediction.outputs[\"endpoint\"],\n",
    "                                                             \"v3io_container\" : V3IO_CONTAINER,\n",
    "                                                             \"stocks_kv\" : STOCKS_KV_TABLE,\n",
    "                                                             \"stocks_tsdb\" : STOCKS_TSDB_TABLE,\n",
    "                                                             \"grafana_url\" : \"http://grafana\"},\n",
    "                                                   handler = \"handler\").after(grafana_viewer,rnn_model_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/User/aviaIguazio/demos/stock-analysis\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(os.path.abspath(project.context)))\n",
    "project.set_workflow('main', os.path.join(os.path.abspath(project.context), 'code', 'workflow.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save(os.path.join(project.context, 'project.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run workflow\n",
    "In this cell we will run the `main` workflow via `KubeFlow Pipelines` on top of our cluster.  \n",
    "Running the pipeline may take some time. Due to possible jupyter timeout, it's best to track the pipeline's progress via KFP or the MLRun UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-11-29 09:19:24,556 [info] submitted pipeline stocks-avia-main 2021-11-29 09-19-23 id=d743d8ff-bd86-4e51-9a10-39b1146eacfa\n",
      "> 2021-11-29 09:19:24,557 [info] Pipeline run id=d743d8ff-bd86-4e51-9a10-39b1146eacfa, check UI for progress\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Pipeline started in project stocks-avia id=d743d8ff-bd86-4e51-9a10-39b1146eacfa<div><a href=\"https://dashboard.default-tenant.app.app-lab-eks.iguazio-cd1.com/mlprojects/stocks-avia/jobs\" target=\"_blank\">click here to check progress</a></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d743d8ff-bd86-4e51-9a10-39b1146eacfa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.run('main', arguments={'RUN_TRAINER': False}, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
